"use strict";
// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.MergedMediaStreamProvider = exports.VideoTransformDeviceMediaStreamProvider = exports.FileMediaStreamProvider = exports.ScreenShareMediaStreamProvider = exports.AudioGainMediaStreamProvider = exports.SynthesizedStereoMediaStreamProvider = exports.AudioBufferMediaStreamProvider = void 0;
const amazon_chime_sdk_js_1 = require("amazon-chime-sdk-js");
/**
 * [[AudioBufferMediaStreamProvider]] creates a `MediaStream` from a parsed
 * audio buffer file.
 */
class AudioBufferMediaStreamProvider {
    constructor(audioPath, shouldLoop = false) {
        this.audioPath = audioPath;
        this.shouldLoop = shouldLoop;
        this.mediaElementSource = undefined;
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                const resp = yield fetch(this.audioPath);
                const bytes = yield resp.arrayBuffer();
                const audioData = new TextDecoder('utf8').decode(bytes);
                const audio = new Audio('data:audio/mpeg;base64,' + audioData);
                audio.loop = this.shouldLoop;
                audio.crossOrigin = 'anonymous';
                audio.play();
                this.mediaElementSource = audio;
                // @ts-ignore
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const streamDestination = audioContext.createMediaStreamDestination();
                const mediaElementSource = audioContext.createMediaElementSource(audio);
                mediaElementSource.connect(streamDestination);
                return streamDestination.stream;
            }
            catch (e) {
                console.log(`Error fetching audio from ${this.audioPath}: ${e}`);
                return null;
            }
        });
    }
    pause() {
        this.mediaElementSource.pause();
    }
    resume() {
        this.mediaElementSource.play();
    }
}
exports.AudioBufferMediaStreamProvider = AudioBufferMediaStreamProvider;
/**
 * [[SynthesizedStereoMediaStreamProvider]] generates a stereo tone by using 2 `OsciallatorNode`s that
 * produce 2 different frequencies. The output of these 2  nodes is passed through a `ChannelMergerNode` to obtain
 * an audio stream with stereo channels where the left channel contains the samples genrated by one node and the
 * right channel contains samples generated by the other.
 */
class SynthesizedStereoMediaStreamProvider {
    constructor(toneHzLeft, toneHzRight) {
        this.toneHzLeft = toneHzLeft;
        this.toneHzRight = toneHzRight;
        this.mediaElementSource = undefined;
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            const audioContext = amazon_chime_sdk_js_1.DefaultDeviceController.getAudioContext();
            const outputNode = audioContext.createMediaStreamDestination();
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 0.1;
            gainNode.connect(outputNode);
            const oscillatorNodeLeft = audioContext.createOscillator();
            oscillatorNodeLeft.frequency.value = this.toneHzLeft;
            const oscillatorNodeRight = audioContext.createOscillator();
            oscillatorNodeRight.frequency.value = this.toneHzRight;
            const mergerNode = audioContext.createChannelMerger(2);
            oscillatorNodeLeft.connect(mergerNode, 0, 0);
            oscillatorNodeRight.connect(mergerNode, 0, 1);
            mergerNode.connect(gainNode);
            oscillatorNodeLeft.start();
            oscillatorNodeRight.start();
            return outputNode.stream;
        });
    }
    pause() {
        // No point since synthesized
    }
    resume() {
        // No point since synthesized
    }
}
exports.SynthesizedStereoMediaStreamProvider = SynthesizedStereoMediaStreamProvider;
/**
 * [[AudioGainMediaStreamProvider]] wraps another [[MediaStreamProvider]] and applies some amount of audio gain.
 * It will discard any video tracks in the process, use [[MergedMediaStreamProvider]] if needed to recombine.
 */
class AudioGainMediaStreamProvider {
    constructor(streamProvider, gain) {
        this.streamProvider = streamProvider;
        this.gain = gain;
        this.context = new AudioContext();
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            const inputMediaStream = yield this.streamProvider.getMediaStream();
            var mediaStreamSource = this.context.createMediaStreamSource(inputMediaStream);
            var destination = this.context.createMediaStreamDestination();
            var gain = this.context.createGain();
            gain.gain.value = this.gain;
            mediaStreamSource.connect(gain);
            gain.connect(destination);
            // Clone video tracks
            for (const videoTrack of inputMediaStream.getVideoTracks()) {
                destination.stream.addTrack(videoTrack);
            }
            return destination.stream;
        });
    }
    pause() {
        this.streamProvider.pause();
    }
    resume() {
        this.streamProvider.resume();
    }
}
exports.AudioGainMediaStreamProvider = AudioGainMediaStreamProvider;
/**
 * [[ScreenShareMediaStreamProvider]] wraps the `MediaStream` returned by a `getUserMediaCall`
 */
class ScreenShareMediaStreamProvider {
    constructor(framerate) {
        this.framerate = framerate;
        this.mediaStream = undefined;
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.mediaStream !== undefined) {
                return Promise.resolve(this.mediaStream);
            }
            // @ts-ignore https://github.com/microsoft/TypeScript/issues/31821
            this.mediaStream = navigator.mediaDevices.getDisplayMedia({
                audio: true,
                video: {
                    frameRate: {
                        max: this.framerate,
                    },
                },
            });
            return this.mediaStream;
        });
    }
    pause() {
        // Nothing to pause
    }
    resume() {
        // Nothing to resume
    }
}
exports.ScreenShareMediaStreamProvider = ScreenShareMediaStreamProvider;
/**
 * [[FileMediaStreamProvider]] emits a media stream corresponding to audio/video found at the
 * provided URI.
 */
class FileMediaStreamProvider {
    constructor(path) {
        this.mediaElementSource = undefined;
        this.mediaElementSource = document.getElementById('content-share-video');
        this.mediaElementSource.src = path;
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            return this.playToStream(this.mediaElementSource);
        });
    }
    playToStream(videoFile) {
        return __awaiter(this, void 0, void 0, function* () {
            yield videoFile.play();
            if (new amazon_chime_sdk_js_1.DefaultBrowserBehavior().hasFirefoxWebRTC()) {
                // @ts-ignore
                return videoFile.mozCaptureStream();
            }
            // @ts-ignore
            return videoFile.captureStream();
        });
    }
    pause() {
        this.mediaElementSource.pause();
    }
    resume() {
        this.mediaElementSource.play();
    }
}
exports.FileMediaStreamProvider = FileMediaStreamProvider;
/**
 * [[VideoTransformDeviceMediaStreamProvider]] emits a media stream corresponding to a [[VideoTransformDevice]]
 */
class VideoTransformDeviceMediaStreamProvider {
    constructor(streamProvider, transformDevice) {
        this.streamProvider = streamProvider;
        this.transformDevice = transformDevice;
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            return this.transformDevice.transformStream(yield this.streamProvider.getMediaStream());
        });
    }
    pause() {
        this.streamProvider.pause();
    }
    resume() {
        this.streamProvider.resume();
    }
}
exports.VideoTransformDeviceMediaStreamProvider = VideoTransformDeviceMediaStreamProvider;
/**
 * [[MergedMediaStreamProvider]] combines the audio from one [[MediaStreamProvider]] with
 * video from another [[MediaStreamProvider]]
 */
class MergedMediaStreamProvider {
    constructor(audioStream, videoStream) {
        this.audioStream = audioStream;
        this.videoStream = videoStream;
        this.outputStream = new MediaStream();
    }
    getMediaStream() {
        return __awaiter(this, void 0, void 0, function* () {
            // WARNING: For currently unknown reasons this only works when cloned audio tracks are
            // added first. If added second no audio will be sent.
            for (const videoTrack of (yield this.videoStream.getMediaStream()).getVideoTracks()) {
                console.log(`Adding video track ${videoTrack.id} to merged media stream`);
                this.outputStream.addTrack(videoTrack.clone());
            }
            for (const audioTrack of (yield this.audioStream.getMediaStream()).getAudioTracks()) {
                console.log(`Adding audio track ${audioTrack.id} to merged media stream`);
                this.outputStream.addTrack(audioTrack.clone());
            }
            return Promise.resolve(this.outputStream);
        });
    }
    pause() {
        this.audioStream.pause();
        this.videoStream.pause();
    }
    resume() {
        this.audioStream.resume();
        this.videoStream.resume();
    }
}
exports.MergedMediaStreamProvider = MergedMediaStreamProvider;
//# sourceMappingURL=DemoMediaStreamProviders.js.map